% scripts to analyze Goby fast start behavioral and performance data. Gobies were startled in a flow tunnel under some combination of a 1) Flow Level and 2) Stimulus Direction. Flow Level has three levels (zero cm/s, xxx cm/s, xxx cm/s). Stimulus Direciton has three levels (cranial, lateral, caudal)

% Created by Jeffrey A. Walker

% Created Sept 7, 2015
% Started with scripts in "goby_analysis.old.R", created August 18, 2015
% note that I used "front", "side", "back" in place of "cranial", "lateral", "caudal" when working with "goby_analysis.old.R" but modified to Kelly's usage on 9/7/15

\documentclass{article}

\begin{document}

\section{github}
The steps to maintain these scripts at GitHub are
\begin{enumerate}
\item Create a new repository at GitHub. Be sure to add the MIT license
\item Copy the SSH clone URL, which is git@github.com:middleprofessor/Goby.git
\item Create a new project in R studio using New Project > Version Control
\item Paste in the GitHub SSH clone URL
\item done!
\end{enumerate}

\section{Load libraries}
The main data libraries are data.table and ggplot2
<< libraries >>=
library(data.table)
library(ggplot2)
library(grid) # necessary for ggplot2
library(gridExtra) #grid.arrange
library(doBy)
library(lsmeans) # lsmeans
library(car) # Anova (type III ss)
library(pscl) # R^2 for glm
library(arm) # display function
@

\section{Create working data.table}
\subsection{Pre-processing steps}
\begin{enumerate}
\item Saved the sheet "overall" in the .xlxs file "Goby lab notebook 18August15\_cleaned up.xlsx" to a tab-delimited text file "goby\_data.txt".
\item Two values in the Fineness Ratio column contained Div by 0 errors - these were changed to NA.
\item The missing values were left as is (not changed to NA).
\item The column headers were changed to "ID  Response	Escape\_Angle	Attack\_Angle	Flow	Direction	Fineness	Vel\_max	Accel\_max"
\end{enumerate}

\subsection{Read and clean data}
<< Read and clean data >>=

write_it <- FALSE # write clean data to file?
# read in text file, add columns, and sort factor levels. 
fn <- 'goby_data.txt'
goby <- data.table(read.table(fn,header=TRUE,sep='\t'))

# substitute meaningful factor level labels. The order must correspond to the coding in the columns 'Flow' and 'Direction' in the text file, which is albetical order.
flow_levels <- c('none','low','high') # these must be in the order
stimulus_direction_levels <- c('caudal','cranial','lateral')
goby[,Flow_Level:=factor(flow_levels[Flow])]
goby[,Stimulus_Direction:=factor(stimulus_direction_levels[Direction])]

# reorder factor levels
new_order <- c(which(levels(goby[,Stimulus_Direction])=='cranial'),
               which(levels(goby[,Stimulus_Direction])=='lateral'),
               which(levels(goby[,Stimulus_Direction])=='caudal'))
goby[,Stimulus_Direction:=factor(Stimulus_Direction,levels(Stimulus_Direction)[new_order])]

new_order <- c(which(levels(goby[,Flow_Level])=='none'),
               which(levels(goby[,Flow_Level])=='low'),
               which(levels(goby[,Flow_Level])=='high'))
goby[,Flow_Level:=factor(Flow_Level,levels(Flow_Level)[new_order])]
if(write_it==TRUE){
  fn.out <- 'goby_data_clean.txt'
  write.table(goby,fn.out,sep='\t',row.names=FALSE,quote=FALSE) 
}


@

Common functions for analyzing the different variables need to be run
<< Analysis functions >>=
expit <- function(x) {exp(x)/(1+exp(x))} # the inverse logit function. This generates the probability of the event p

all_models_lm <- function(sub_goby,logistic=FALSE){
  # sub_goby contains the Y variable in column 'Y'. This could be Response, Escape Angle, Max Vel, Max Accel
  # if logistic=TRUE then use GLM
  
  options(contrasts=c("contr.treatment", "contr.poly"))
  # 3 variable models
  model1 <- lm(Y~FL*SD*FR, data=sub_goby)
  model2 <- lm(Y~FL*SD*FR - FL:SD:FR, data=sub_goby)
  model2b <- lm(Y~SD*FL*FR - SD:FL:FR, data=sub_goby)
  model3a <- lm(Y~FL*SD + FL*FR, data=sub_goby)
  model3b <- lm(Y~SD*FL + SD*FR, data=sub_goby)
  model3c <- lm(Y~FR*FL + FR*SD, data=sub_goby)
  model4a <- lm(Y~FR+FL*SD, data=sub_goby)
  model4b <- lm(Y~FL+SD*FR, data=sub_goby)
  model4c <- lm(Y~SD+FL*FR, data=sub_goby)
  model5 <- lm(Y~FL+SD+FR, data=sub_goby)
  
  # 2 variable models
  model6 <- lm(Y~FL*SD, data=sub_goby)
  model7 <- lm(Y~FL+SD, data=sub_goby)
  
  model8 <- lm(Y~FL*FR, data=sub_goby)
  model9 <- lm(Y~FL+FR, data=sub_goby)
  
  model10 <- lm(Y~SD*FR, data=sub_goby)
  model11 <- lm(Y~SD+FR, data=sub_goby)
  
  # single variable models
  model12 <- lm(Y~SD, data=sub_goby)
  model13 <- lm(Y~FL, data=sub_goby)
  model14 <- lm(Y~FR, data=sub_goby)
  
  mlist <- list(model1,model2,model3a,model3b,model3c,model4a,model4b,model4c,model5,model6,model7,model8,model9,model10,model11,model12,model13,model14)
  # get formula of each model
  model <- NULL
  for(i in 1:length(mlist)){
    vars <- row.names(anova(mlist[[i]]))
    vars <- vars[-length(vars)]
    new_model <- vars[1]
    if(length(vars) > 1){
      for(j in 2:length(vars)){new_model<-paste(new_model,vars[j],sep=' + ')}
    }
    model <- c(model,new_model)
  }
  
  # get AIC. Note that AIC() returns a different value than extractAIC() but only by a constant so compared to minimum this is the same
  aic <- unlist(lapply(mlist,AIC))
  aic_rel <- aic-min(aic)
  
  # get adjusted R squared
  rsqr <- numeric(length(aic))
  for(i in 1:length(rsqr)){rsqr[i] <- summary(mlist[[i]])$adj.r.squared}
  
  # get P-value for last term in model
  pvalue <- numeric(length(aic))
  for(i in 1:length(pvalue)){
    plist <- anova(mlist[[i]])$Pr
    pvalue[i] <- plist[length(plist)-1]
  }
  
  # make output table
  my_table <- data.table(model=model,delta_AIC=round(aic_rel,1),adj_R2=round(rsqr,3),p_value=round(pvalue,3))
  my_table <- orderBy(~delta_AIC,my_table)
  
  return(my_table)
}

all_models_glm <- function(sub_goby,logistic=FALSE){
  # sub_goby contains the Y variable in column 'Y'. This could be Response, Escape Angle, Max Vel, Max Accel
  # if logistic=TRUE then use GLM
  
  options(contrasts=c("contr.treatment", "contr.poly"))
  # 3 variable models
  null_mod <- glm(Y~1, family=binomial(link='logit'), data=sub_goby)

  model1 <- glm(Y~FL*SD*FR, family=binomial(link='logit'), data=sub_goby)
  model2 <- glm(Y~FL*SD*FR - FL:SD:FR, family=binomial(link='logit'), data=sub_goby)
  model2b <- glm(Y~SD*FL*FR - SD:FL:FR, family=binomial(link='logit'), data=sub_goby)
  model3a <- glm(Y~FL*SD + FL*FR, family=binomial(link='logit'), data=sub_goby)
  model3b <- glm(Y~SD*FL + SD*FR, family=binomial(link='logit'), data=sub_goby)
  model3c <- glm(Y~FR*FL + FR*SD, family=binomial(link='logit'), data=sub_goby)
  model4a <- glm(Y~FR+FL*SD, family=binomial(link='logit'), data=sub_goby)
  model4b <- glm(Y~FL+SD*FR, family=binomial(link='logit'), data=sub_goby)
  model4c <- glm(Y~SD+FL*FR, family=binomial(link='logit'), data=sub_goby)
  model5 <- glm(Y~FL+SD+FR, family=binomial(link='logit'), data=sub_goby)
  
  # 2 variable models
  model6 <- glm(Y~FL*SD, family=binomial(link='logit'), data=sub_goby)
  model7 <- glm(Y~FL+SD, family=binomial(link='logit'), data=sub_goby)
  
  model8 <- glm(Y~FL*FR, family=binomial(link='logit'), data=sub_goby)
  model9 <- glm(Y~FL+FR, family=binomial(link='logit'), data=sub_goby)
  
  model10 <- glm(Y~SD*FR, family=binomial(link='logit'), data=sub_goby)
  model11 <- glm(Y~SD+FR, family=binomial(link='logit'), data=sub_goby)
  
  # single variable models
  model12 <- glm(Y~SD, family=binomial(link='logit'), data=sub_goby)
  model13 <- glm(Y~FL, family=binomial(link='logit'), data=sub_goby)
  model14 <- glm(Y~FR, family=binomial(link='logit'), data=sub_goby)
  
  mlist <- list(model1,model2,model3a,model3b,model3c,model4a,model4b,model4c,model5,model6,model7,model8,model9,model10,model11,model12,model13,model14)
  # get formula of each model
  model <- NULL
  for(i in 1:length(mlist)){
    vars <- row.names(anova(mlist[[i]]))[-1] # differs from anova(lm)
    # vars <- vars[-length(vars)] # differs from anova(lm)
    new_model <- vars[1]
    if(length(vars) > 1){
      for(j in 2:length(vars)){new_model<-paste(new_model,vars[j],sep=' + ')}
    }
    model <- c(model,new_model)
  }
  
  # get AIC. Note that AIC() returns a different value than extractAIC() but only by a constant so compared to minimum this is the same
  aic <- unlist(lapply(mlist,AIC))
  aic_rel <- aic-min(aic)
  
  # get R squared
  rsqr <- numeric(length(aic))
  adj_rsqr <- numeric(length(aic))
  for(i in 1:length(rsqr)){
    yhat <- expit(predict(mlist[[i]]))
    # rsqr[i] <- mean(yhat[which(sub_goby[,Y]==1)]) - mean(yhat[which(sub_goby[,Y]==0)]) # Tjur method
    rsqr[i] <- pR2(mlist[[i]])['McFadden'] # McFadden's R2
    # compute adjusted McFadden's
    k <- extractAIC(mlist[[i]])[1]
    adj_rsqr[i] <- (1-(logLik(mlist[[i]])-k)/logLik(null_mod))[1]
  }
  
  # get P-value for last term in model
  pvalue <- numeric(length(aic))
  for(i in 1:length(pvalue)){
    plist <- anova(mlist[[i]],test="Chisq")$Pr
    pvalue[i] <- plist[length(plist)]
  }
  
  # make output table
  my_table <- data.table(model=model,delta_AIC=round(aic_rel,1),R2=round(rsqr,3),adj_R2=round(adj_rsqr,3),p_value=round(pvalue,3))
  my_table <- orderBy(~delta_AIC,my_table)
  
  return(my_table)
}

@

\section{Analysis}
\subsection{Analyze the frequency of the response to the stimulus}

First, subset the data to that with no missing values for the relevant variables, including Fineness Ratio.

<< Analyze Response>>=
sub_goby <- na.omit(goby[,list(Response,Stimulus_Direction,Flow_Level,Fineness)])
full_names <- colnames(sub_goby)
short_names <- c('Y','SD','FL','FR') # make sure in same order as full_names!
@

First create a table of the frequency of response by class
<<>>=
# table of frequency of response by class. Response must be numeric
sub_goby[,Response:=as.numeric(as.character(Response))]
response_table <- sub_goby[,list(N=.N,freq=sum(Response)),by=list(Flow_Level,Stimulus_Direction)]
response_table[,Percent_Responding:=freq/N]
@

Compute the overall frequency of response

<<>>=
# (unweighted) overall frequency of response (not the mean by class). These are both the same
sub_goby[,list(overall_f=mean(Response))]
response_table[,list(overall_f=sum(freq)/sum(N))]
# (weighted) overall frequency (mean of frequencies by class)
response_table[,list(overall_f=mean(freq/N))]
@
The overall rate of resonse is 0.77. 

@

Explore P-values in Type I SS ANOVA table.

<<>>=
fit1 <- glm(Response~Fineness*Stimulus_Direction*Flow_Level,family=binomial(link='logit'),data=sub_goby)
fit2 <- glm(Response~Fineness*Stimulus_Direction*Flow_Level - Fineness:Stimulus_Direction:Flow_Level,family=binomial(link='logit'),data=sub_goby)
anova(fit1,fit2,test="Chisq")
anova(fit1,test="Chisq")
@

The results suggests that the 3-way interaction is perhaps not ignorable, that is fineness has no consistent effect across Stimulus Direction and Flow Level.

Analyze all models and compare using AIC and pseudo-$R^2$

<<>>=
# use this for all_models_glm
sub_goby <- setNames(sub_goby,short_names)
#  sub_goby[,Fineness:=scale(Fineness)]
all_models_glm(sub_goby)
@

This suggests focussing on the model FL + SD + FL:SD to estimate effect sizes. Recreate subset without Fineness.
<<>>=
# also note there are two more observations in this data since FR is removed
sub_goby <- na.omit(goby[,list(Response,Stimulus_Direction,Flow_Level)])
# descriptive stats
@

We want to create a plot showing the response as a function of Flow Level, Stimulus Direction and their interaction. Start by creating a response table, which shows the frequency of response as a function of Flow Level X Stimulus Direction, and compute the overall response as the mean ignoring cells and as the weighted mean of the cells.

Fit the factorial and additive models 
<<>>=
# now make Response a factor!
sub_goby[,Response:=factor(Response)]
# compare full factorial vs. additive models
# result is the full model is necessary
# P interaction is .001488
fit1 <- glm(Response~Stimulus_Direction*Flow_Level,family=binomial(link='logit'),data=sub_goby)
fitR <- glm(Response~Flow_Level*Stimulus_Direction,family=binomial(link='logit'),data=sub_goby)
fit2 <- glm(Response~Stimulus_Direction+Flow_Level,family=binomial(link='logit'),data=sub_goby)
anova(fit1,fit2,test="Chisq")
anova(fit1,test="Chisq") # note same P-value
@
 
Explore the fit with a figure, but using the lsmip function
<<>>=
# exploratory figure of response frequency
lsmip(fit1,Flow_Level~Stimulus_Direction,type='response') # compare this to the response_table above
@

Estimate effect sizes and confidence intervals
<<>>=
# get lsmeans and 95% CI from glm model.
glm_lsmeans <- lsmeans(fit1,~Flow_Level|Stimulus_Direction)
glm_lsmeans
@

Create a table of effect size and confidence interval using lsmeans package. Ultimately I cannot figure out how to access the return values so I replace this below using the glm package and base R commands
<<>>=
# I don't know how to access these means other than manually inputing into a text file and
# reading in that! So, output these results and edit to readable table: lsmean_table_response.txt
glm_lsmeans_table <- data.table(read.table('lsmean_table_response.txt',header=TRUE,sep='\t'))
glm_lsmeans_table[,lsmean:=expit(lsmean)]
glm_lsmeans_table[,asymp.LCL:=expit(asymp.LCL)]
glm_lsmeans_table[,asymp.UCL:=expit(asymp.UCL)]
my_table <- merge(response_table,glm_lsmeans_table,by=c('Stimulus_Direction','Flow_Level'))
my_table
@

Create a table of effect size and confidence intervals using glm and base R commands
<<>>=
yhat.test <- predict(fit1, se.fit=TRUE)
yhat <- predict(fit1, type="link", se.fit=TRUE)
head(yhat.test$fit)
head(yhat$fit)
head(yhat.test$se)
head(yhat$se)  # not sure what "link" does since the return values are the same

crit_val <- 1.96 ## approx 95% CI
upr <- yhat$fit + (crit_val * yhat$se.fit)
lwr <- yhat$fit - (crit_val * yhat$se.fit)
sub_goby[,yhat:=yhat$fit]
sub_goby[,upr:=upr]
sub_goby[,lwr:=lwr]
predict_table <- sub_goby[,list(yhat=mean(expit(y_hat)),lwr=mean(expit(lwr)),upr=mean(expit(upr))),by=list(Flow_Level,Stimulus_Direction)]
# check same as lsmeans

# by hand
coef <- coefficients(fit1)
ci <- confint(fit1)
# based on effects, create treatment columns. Don't know how to do this except manually
ci_table <- data.table(effect=row.names(ci),coef=coef,ci)

# compare to lsmeans
coeff.lateral.low <- 2.1972246 + (-.9734491) + (-0.9734491) + (-.12516)
expit(coeff.lateral.low) # check
lower.lateral.low <- (-2.2269572)
expit(lower.lateral.low) # no
@

Use the base R result (equivalent to the lsmeans result but I don't have to create parts by hand) to plot and save as a figure
<<>>=
# plot with 95% CI
ref <- 0 # set to 1 for "failure to respond" or zero for "respond"
pd <- position_dodge(.3)  
gg1 <- ggplot(data=predict_table,aes(x=Stimulus_Direction,y=abs(ref-yhat),shape=Flow_Level, group=Flow_Level))
gg1 <- gg1 + geom_errorbar(aes(ymin=abs(ref-lwr), ymax=abs(ref-upr)), width=.3, position=pd, color="gray70")
gg1 <- gg1 + geom_line(position=pd,color='black')
gg1 <- gg1 + geom_point(position=pd,size=3,color='black')
if(ref==1){
  gg1 <- gg1 + scale_y_continuous(name='Frequency of Failed Response')    
}else{
  gg1 <- gg1 + scale_y_continuous(name='Frequency of Response')    
}
gg1 <- gg1 + scale_x_discrete(name='Stimulus Direction')
#gg1 <- gg1 + ggtitle('A')
gg1 <- gg1 + theme_bw()
gg1 <- gg1 + theme(plot.margin=unit(x=c(0.1,0.1,0.1,0.1),'cm'),text=element_text(size=9),plot.title=element_text(hjust=0),legend.position=c('right'))
gg1 # change symbols to reflect group and errorbars = gray
gg1

# save gg1 as FigJAW01
fig_name <- 'FigJAW01.pdf'
w <- 3.5
h <- 3
pdf(fig_name,paper='special',onefile=FALSE,width=w,height=h)
print(gg1)
dev.off()
@

loglinear exploration
<<>>=

# log-linear analyses
ctable <- table(sub_goby)
ftable <- as.data.frame(ctable)
# using glm
fit1 <- glm(Freq ~ Response*Stimulus_Direction*Flow_Level, data=ftable, family=poisson)
fit2 <- glm(Freq ~ Response*Stimulus_Direction+Flow_Level, data=ftable, family=poisson)

# note the Likelihood Ratio P value is the same as the logistic regression above
loglm(~Response*Stimulus_Direction*Flow_Level,data=ctable)
loglm(~Response*Stimulus_Direction*Flow_Level - Response:Stimulus_Direction:Flow_Level,data=ctable)

mosaicplot(ctable, shade=T) 

@


\subsection{Analyze Escape Angle}

First compute Summary statistics using observations with complete Stimulus Direction + Flow Level data
<< Analyze Escape Angle>>=
# means by cell
means_table <- goby[,list(mean_angle=mean(Escape_Angle,na.rm=TRUE)),by=list(Flow_Level,Stimulus_Direction)]
# cell with minimum escape angle
means_table[mean_angle==min(means_table[,mean_angle]),]
# cell with maximum escape angle
means_table[mean_angle==max(means_table[,mean_angle]),]
# unweighted mean of cell means ignoring unbalanced cells
mean(means_table[,mean_angle])
# weighted mean of cells by N = mean ignoring group structure, use this mean
goby[,list(mean=mean(Escape_Angle,na.rm=TRUE))] # grand mean

@

Do variable-selection using subset of goby with complete observations for Stimulus Direction + Flow Level + Fineness (two fewer observations than above)
<< >>=
# subset the data to that with no missing values for the relevant variables, including Fineness Ratio.
sub_goby <- na.omit(goby[,list(Escape_Angle,Stimulus_Direction,Flow_Level,Fineness)])
full_names <- colnames(sub_goby)
short_names <- c('Y','SD','FL','FR') # make sure in same order as full_names!
setnames(sub_goby,short_names)
all_models_lm(sub_goby)
@
SD alone is the best model. Adding FR trivially drops adjusted $R^2$ and the P-value is .33 yet $\Delta$AIC is only 1.0. The model with all main effects plus the FL $\times$ FR interaction is a reasonable candidate model ($\Delta$AIC = 1.7, $R^2=.12$) and the interaction is statistically significant (P = .042).

Use the model 6 graph (FL + SD) to show the SD but not FL effect and no interaction. Add comments on model 2, at least and maybe 3.

<<>>=
# subset the data not including Fineness. This will have two more rows than the data used for the variable selection analysis above because of the two observations with missing fineness
sub_goby <- na.omit(goby[,list(Escape_Angle,Stimulus_Direction,Flow_Level)])
sum_table <- sub_goby[,list(N=.N,ybar=mean(Escape_Angle),ysd=sd(Escape_Angle)),by=list(Stimulus_Direction,Flow_Level)]
sum_table[,se:=ysd/sqrt(N)]
sum_table[,tcrit:=qt(0.975, df= N-1)]
sum_table[,ci:=se*tcrit]

pd <- position_dodge(0.25)
gg1 <- ggplot(data=sum_table,aes(x=Stimulus_Direction,y=ybar,color=Flow_Level, group=Flow_Level))
gg1 <- gg1 + geom_errorbar(aes(ymin=ybar-ci, ymax=ybar+ci), width=1, position=pd)
gg1 <- gg1 + geom_line(position=pd)
gg1 <- gg1 + geom_point(position=pd,size=3)
gg1 <- gg1 + scale_y_continuous(name='Escape Angle')
gg1 <- gg1 + scale_x_discrete(name='Stimulus Direction')
#gg1 <- gg1 + ggtitle('A')
gg1 <- gg1 + theme(plot.margin=unit(x=c(0.1,0.1,0.1,0.1),'cm'),text=element_text(size=9),plot.title=element_text(hjust=0),legend.position=c('right'))
gg1

#save gg1 as FigJAW02
fig_name <- 'Fig.JAW02.pdf'
w <- 3.5
h <- 2.5
pdf(fig_name,paper='special',onefile=FALSE,width=w,height=h)
print(gg1)
dev.off()


@

Estimate Stimulus Direction effects ignoring Flow Level (and Fineness).

<<>>=
fit <- lm(Escape_Angle~Stimulus_Direction,data=sub_goby)
display(fit) # get difference from cranial 
confint(fit) # get 95% CI on difference from cranial
@

Fish stimulated cranially increase escape angle by 24.4 (95$\%$ CI: 10.4 - 38.3) relative to laterally stimulated and 25.0 (95$\%$ CI: 12.1 = 37.8) relative to  caudally stimulated fish.

Now explore the Flow Level by Fineness Ratio effect. Need to remove observations with missig fineness
<<>>=
sub_goby <- na.omit(goby[,list(Escape_Angle,Stimulus_Direction,Flow_Level,Fineness)])
fit <- lm(Escape_Angle~Stimulus_Direction+Flow_Level+Fineness+Flow_Level*Fineness,data=sub_goby)
display(fit)
coefs <- display(fit)$coef[6:8]
slopes <- coefs
slopes[2:3] <- coefs[2:3]+coefs[1]
ci.coef <- confint(fit)[6:8,]
ci.slope <- ci.coef
ci.slope[2:3,] <- coefs[1] + ci.slope[2:3,]
coef.table <- data.frame(coef=coefs,ci.coef)
slope.table <- data.frame(slope=slopes,ci.slope)

@
The slopes are not statistically significant in any group. What is statistically signficant is the interaction, so that the slope in the low flow level is statistically significantly less than that in zero flow. So, how to report this (if at all), especially since the pattern is not super interpretable (or sure, I can make up an explanation but this requires handwaving for why the effect is non-linear. Or maybe just interpret it as, when there is a flow, the effect of fineness becomes more negative)


Adjusting for Stimulus Direction, Escape Angle increases 10.6° per unit Fineness when Flow Level is zero, -15.0° per unit Fineness when Flow level is low and -4.7° per unit Fineness when Flow level is moderate. The standard errors for these effects. Another (better?) way to state this since it's the interaction is: Relative to the zero flow condition, the effect of Fineness on Escape Angle decreases 25.6° per unit Fineness (95$\%$ CI: 5.6 - 45) in the low flow treatment and decreases 15.3° per unit Fineness (95$\%s$ CI: -5.6 - 36.2) in the high flow treatment.

Or another way. Adjusting for Stimulus Direction, Escape Angle increases 10.6° per unit Fineness when Flow Level is zero. In the low flow condition, the Fineness effect decreases 25.6° per unit Fineness (95$\%$ CI: 5.6 - 45) from the zero. In the high flow condition, the Fineness effect decreases 15.3° per unit Fineness (95$\%$ CI: -5.6 - 36.2)

\subsection{Analyze Velocity}
Subset the data and get mean velocity by cell and grand mean
<< analyze Velocity >>=
sub_goby <- na.omit(goby[,list(Vel_max,Stimulus_Direction,Flow_Level)])
# grand mean
sub_goby[,list(grand_mean=mean(Vel_max))]
# cell means
sub_goby[,list(grand_mean=mean(Vel_max)),by=list(Stimulus_Direction,Flow_Level)]
@

What is reported will be determined by the variable selection analysis. So do variable selection
<<>>=
sub_goby <- na.omit(goby[,list(Vel_max,Stimulus_Direction,Flow_Level,Fineness)])
full_names <- colnames(sub_goby)
short_names <- c('Y','SD','FL','FR') # make sure in same order as full_names!
setnames(sub_goby,short_names)
all_models_lm(sub_goby)
@
The model with the highest adjusted $R^2$ (0.03) has the lowest delta AIC! Regardless, there is nothing to interpret here. There is too much noise to get good estimates of the small effects.

So for the results, just report the grand mean velocity. No combination of Stimulus Direction, Flow Level, and Fineness Ratio explained more than $3\%$ of the variance in Maximum Escape Velocity (so not worth reporting on the top AIC model)

\subsection{Analyze Acceleration}
Subset the data and get mean max Acceleration by cell and grand mean
<< analyze Acceleration >>=
sub_goby <- na.omit(goby[,list(Accel_max,Stimulus_Direction,Flow_Level)])
# grand mean
sub_goby[,list(grand_mean=mean(Accel_max))]
# cell means
sub_goby[,list(grand_mean=mean(Accel_max)),by=list(Stimulus_Direction,Flow_Level)]
@
The grand mean acceleration is 79.6 $m s^2$. 

What is reported will be determined by the variable selection analysis. So do variable selection
<<>>=
sub_goby <- na.omit(goby[,list(Accel_max,Stimulus_Direction,Flow_Level,Fineness)])
full_names <- colnames(sub_goby)
short_names <- c('Y','SD','FL','FR') # make sure in same order as full_names!
setnames(sub_goby,short_names)
all_models_lm(sub_goby)
@
The lowest AIC model is SD*FR and the P-value of the interaction is 0.093, so perhaps not ignorable. The 2nd lowest AIC model is the additive model (SD + FR) and the p-value for the FR effect is 0.007. The 3rd and 4 best models also include the SD:FR interaction and both with smallish P-values. This suggests reporting the effect sizes including the interaction and showing an interaction plot.

Note that as we go from a model with FR to SD + FR to SD*FR the adjusted $R^2$ rises from .035 to .056 to .075.

<<>>=
sub_goby <- na.omit(goby[,list(Y=Accel_max,Stimulus_Direction,Flow_Level,Fineness)])

# Stimulus_Direction*Fineness model
fit <- lm(Y~Stimulus_Direction*Fineness,data=sub_goby)
sub_goby[,yhat1:=predict(fit)]
gg1 <- ggplot(data=sub_goby,aes(x=Fineness,y=Y/100,color=Stimulus_Direction))
gg1 <- gg1 + geom_point()
gg1 <- gg1 + geom_line(aes(y = yhat1/100))
gg1 <- gg1 + scale_y_continuous(name='Acceleration (cm/s/s)')
gg1 <- gg1 + theme(plot.margin=unit(x=c(0.1,0.1,0.1,0.1),'cm'),text=element_text(size=9),plot.title=element_text(hjust=0),legend.position=c('right'))
gg1

# save gg1 as FigJAW03
fig_name <- 'FigJAW03.pdf'
w <- 3.5
h <- 3
pdf(fig_name,paper='special',onefile=FALSE,width=w,height=h)
print(gg1)
dev.off()

@

It's not pretty (low $R^2$) but does show the interesting change in FR effect from cranial to lateral to caudal stimulus direction (is this an illusion of N=3?). We need to turn the graph into effect sizes

<<>>=
display(fit) # assuming fit was fit above
confint(fit)
coefs <- display(fit)$coef[4:6]
slopes <- coefs
slopes[2:3] <- coefs[2:3]+coefs[1]
ci.coef <- confint(fit)[4:6,]
ci.slope <- ci.coef
ci.slope[2:3,] <- coefs[1] + ci.slope[2:3,]
coef.table <- data.frame(coef=coefs,ci.coef)
slope.table <- data.frame(slope=slopes,ci.slope)/100 # convert to m/s/s
@
Ignoring Flow Level, Max acceleration increases 25.5 ms$^2$ per unit Fineness in the cranially stimulated fish
\end{document}